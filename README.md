<div align="center">

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                              â•‘
â•‘    â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                 â•‘
â•‘    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•                 â•‘
â•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•¦â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                   â•‘
â•‘    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•                   â•‘
â•‘    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•¦â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                 â•‘
â•‘    â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•                 â•‘
â•‘                                                              â•‘
â•‘         â—†  A I   L E A D E R S H I P   A N A L Y S T  â—†     â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### *Ask anything. Get answers grounded in real financial documents.*

[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![LangChain](https://img.shields.io/badge/LangChain-Orchestration-1C3C3C?style=for-the-badge&logo=chainlink&logoColor=white)](https://langchain.com)
[![Groq](https://img.shields.io/badge/Groq-Lightning%20Fast-F55036?style=for-the-badge)](https://groq.com)
[![FAISS](https://img.shields.io/badge/FAISS-Vector%20Search-0064A5?style=for-the-badge)](https://github.com/facebookresearch/faiss)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—%20HuggingFace-Embeddings-FFD21E?style=for-the-badge)](https://huggingface.co)

</div>

---

## â—ˆ What Is This?

> **A RAG-powered analyst that lives inside Adobe's financials.**

Drop in any 10-K, 10-Q, or Earnings Release â€” and this agent transforms dense PDFs into instant, citation-backed answers. No hallucinations. No guessing. Every response is anchored to the documents you provide.

```
You ask   â†’  "How did Adobe's net income change in FY2025?"
Agent     â†’  Scans embedded document chunks in milliseconds
Response  â†’  Grounded answer + exact source context. Every time.
```

---

## â—ˆ How It Works

'''
```

---

## â—ˆ System Architecture

<div align="center">

![System Architecture](https://raw.githubusercontent.com/Amruth-varsh/AI-Leadership-Insight-Decision-Agent/main/System%20Architecture.png)

</div>

---

## â—ˆ Tech Stack

| Layer | Tool | Why It's Here |
|---|---|---|
| ğŸ§  **LLM** | Groq `llama-3.3-70b-versatile` | Blazing inference. Real-time responses. |
| ğŸ”— **Orchestration** | LangChain | RAG pipeline, prompt templates, LLM wiring |
| ğŸ—„ï¸ **Vector DB** | FAISS | Facebook's gold-standard similarity search |
| ğŸ”¡ **Embeddings** | HuggingFace `all-MiniLM-L6-v2` | Runs 100% offline after first download |
| ğŸ“„ **PDF Parsing** | PyPDF | Recursive extraction and text cleaning |
| âœ‚ï¸ **Chunking** | Recursive Character Splitter | Configurable size + overlap |
| ğŸ” **Config** | python-dotenv | Secure API key management via `.env` |

---

## â—ˆ Project Structure

```
adobe-ai-analyst/
â”‚
â”œâ”€â”€ ğŸ“„  main.py              â† CLI entry point. Start here.
â”œâ”€â”€ âš™ï¸  config.py            â† All settings loaded from .env
â”œâ”€â”€ ğŸ“‹  requirements.txt     â† Python dependencies
â”œâ”€â”€ ğŸ”  .env                 â† Your API keys (never commit this)
â”‚
â”œâ”€â”€ ğŸ“  data/                â† Drop your PDFs in here
â”œâ”€â”€ ğŸ—„ï¸  faiss_index/         â† Auto-generated vector store
â”œâ”€â”€ ğŸ’¾  outputs/             â† Saved Q&A pairs (timestamped)
â”‚
â””â”€â”€ ğŸ“  src/
    â”œâ”€â”€ ğŸ”§  __init__.py
    â”œâ”€â”€ ğŸ“¥  ingest.py        â† PDF loading & chunking logic
    â”œâ”€â”€ ğŸ”  embeddings.py    â† FAISS index build/load
    â””â”€â”€ ğŸ¤–  agent.py         â† Prompt template + Groq LLM call
```

---

## â—ˆ Setup in 4 Steps

### `1` â€” Create a virtual environment

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Mac / Linux
source venv/bin/activate
```

### `2` â€” Install dependencies

```bash
pip install -r requirements.txt
```

### `3` â€” Configure your `.env`

Create a `.env` file in the root directory:

```env
# â”€â”€ LLM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GROQ_API_KEY=gsk_your_key_here
MODEL_NAME=llama-3.3-70b-versatile

# â”€â”€ Embeddings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# â”€â”€ Retrieval â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOP_K_RESULTS=10
TEMPERATURE=0

# â”€â”€ Chunking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CHUNK_SIZE=1200
CHUNK_OVERLAP=200

# â”€â”€ Paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_FOLDER=./data
OUTPUT_FOLDER=./outputs
```

> **Getting your Groq API Key**
> 1. Go to [console.groq.com](https://console.groq.com) â†’ Sign Up
> 2. Sidebar â†’ **API Keys** â†’ **Create API Key**
> 3. Name it (e.g. `adobe-project`) â†’ Copy immediately
> 4. Key starts with `gsk_...` â€” it's shown **only once**

> **Enabling `llama-3.3-70b-versatile`**
> Console â†’ **Settings** â†’ **Limits** â†’ **Allowed Models** â†’ search & select the model â†’ **Save**

### `4` â€” Add your PDFs

```bash
# Place your financial documents here:
data/
  â”œâ”€â”€ adobe-10k-2024.pdf
  â”œâ”€â”€ adobe-10q-q3-2024.pdf
  â””â”€â”€ adobe-earnings-q4-2024.pdf
```

---

## â—ˆ Usage

```bash
# First run â€” builds the FAISS index automatically
python main.py

# Force re-index (after adding new documents)
python main.py --rebuild

# Verbose debug output
set LOG_LEVEL=DEBUG && python main.py     # Windows
LOG_LEVEL=DEBUG python main.py           # Mac/Linux
```

Type your question at the prompt. Type `exit` or `quit` to stop.

---

## â—ˆ Example Questions to Try

```
â—†  "How did Adobe's net income perform in FY2025 vs FY2024?"
â—†  "What is Adobe's revenue breakdown by segment for FY2024?"
â—†  "How did the Publishing and Advertising segment compare to others?"
â—†  "What is Adobe's FY2026 earnings per share guidance?"
â—†  "How did Digital Media ARR grow year-over-year?"
â—†  "What risks did Adobe highlight in their most recent 10-K?"
```

---

## â—ˆ Important Notes

```
âš ï¸  Never commit .env â€” add it to .gitignore
âš ï¸  FAISS index auto-builds on first run
âš ï¸  Embedding model caches locally â€” no internet needed after first download
âš ï¸  Use --rebuild whenever you add new PDFs to data/
```

---

<div align="center">

```
Built with  âš¡ Groq  Â·  ğŸ¦œ LangChain  Â·  ğŸ¤— HuggingFace  Â·  ğŸ” FAISS
```

*Answers grounded in documents. Never outside them.*

</div>
