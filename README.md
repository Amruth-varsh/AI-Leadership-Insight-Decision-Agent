<div align="center">

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                      â•‘
â•‘    â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•— â•‘
â•‘    â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ â•‘
â•‘    â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘ â•‘
â•‘    â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘ â•‘
â•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ â•‘
â•‘    â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â• â•‘
â•‘                                                                      â•‘
â•‘   â—†  A I  L E A D E R S H I P  I N S I G H T  D E C I S I O N  â—†   â•‘
â•‘                    â—†  A G E N T  â—†                                   â•‘
â•‘                                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### *Ask anything. Get answers grounded in real financial documents.*

[![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![LangChain](https://img.shields.io/badge/LangChain-Orchestration-1C3C3C?style=for-the-badge&logo=chainlink&logoColor=white)](https://langchain.com)
[![Groq](https://img.shields.io/badge/Groq-Lightning%20Fast-F55036?style=for-the-badge)](https://groq.com)
[![FAISS](https://img.shields.io/badge/FAISS-Vector%20Search-0064A5?style=for-the-badge)](https://github.com/facebookresearch/faiss)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—%20HuggingFace-Embeddings-FFD21E?style=for-the-badge)](https://huggingface.co)

</div>

---

## â—ˆ What Is This?

> **A RAG-powered analyst that lives inside financial documents.**

Drop in company documents (e.g.: Annual reports , Quarterly reports , Strategy notes , Operational updates) â€” and this agent transforms dense PDFs into instant, citation-backed answers. No hallucinations. No guessing. Every response is anchored to the documents you provide.

```
You ask   â†’  "How did Adobe's net income change in FY2025?"
Agent     â†’  Scans embedded document chunks in milliseconds
Response  â†’  Grounded answer + exact source context. Every time.
```

---

## â—ˆ System Architecture

<div align="center">

![System Architecture](https://raw.githubusercontent.com/Amruth-varsh/AI-Leadership-Insight-Decision-Agent/main/System%20Architecture.png)

</div>

---

## â—ˆ Tech Stack

| Layer | Tool | Why It's Here |
|---|---|---|
| ğŸ§  **LLM** | Groq `llama-3.3-70b-versatile` | Blazing inference. Real-time responses. |
| ğŸ”— **Orchestration** | LangChain | RAG pipeline, prompt templates, LLM wiring |
| ğŸ—„ï¸ **Vector DB** | FAISS | Facebook's gold-standard similarity search |
| ğŸ”¡ **Embeddings** | HuggingFace `all-MiniLM-L6-v2` | Runs 100% offline after first download |
| ğŸ“„ **PDF Parsing** | PyPDF | Recursive extraction and text cleaning |
| âœ‚ï¸ **Chunking** | Recursive Character Splitter | Configurable size + overlap |
| ğŸ” **Config** | python-dotenv | Secure API key management via `.env` |

---

## â—ˆ Project Structure

```
AI-Leadership-Insight-Decision-Agent/
â”‚
â”œâ”€â”€ ğŸ“„  main.py              â† CLI entry point. Start here.
â”œâ”€â”€ âš™ï¸  config.py            â† All settings loaded from .env
â”œâ”€â”€ ğŸ“‹  requirements.txt     â† Python dependencies
â”œâ”€â”€ ğŸ”  .env                 â† Your API keys
â”‚
â”œâ”€â”€ ğŸ—„ï¸  faiss_index/         â† Auto-generated vector store
â”œâ”€â”€ ğŸ’¾  outputs/             â† Saved Q&A pairs (timestamped)
â”‚
â””â”€â”€ ğŸ“  src/
    â”œâ”€â”€ ğŸ”§  __init__.py
    â”œâ”€â”€ ğŸ“¥  ingest.py        â† PDF loading & chunking logic
    â”œâ”€â”€ ğŸ”  embeddings.py    â† FAISS index build/load
    â””â”€â”€ ğŸ¤–  agent.py         â† Prompt template + Groq LLM call
```

---

## â—ˆ Setup

### 1. Create a virtual environment

```bash
python -m venv venv
venv\Scripts\activate        # Windows
source venv/bin/activate     # Mac/Linux
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Configure `.env`

**Steps to Get Your Groq API Key**

1. Go to [console.groq.com](https://console.groq.com)
2. Click **Sign Up** if you don't have an account (sign up with Google or Email)
3. After logging in, click **API Keys** in the left sidebar
4. Click **Create API Key** (top right)
5. Give it a name like `adobe-project` and click **Submit**
6. Copy your key immediately â€” it starts with `gsk_...` and **will not be shown again**

**How to Enable `llama-3.3-70b-versatile` in Groq Console**

1. Log in to [console.groq.com](https://console.groq.com)
2. Click **Settings** in the left sidebar
3. Click **Limits**
4. Scroll down to the **Allowed Models** section
5. Click the model selection dropdown/search box
6. Type `llama-3.3-70b-versatile` and select it from the list
7. It will appear as a tag/chip in the allowed models box
8. Click **Save**

```env
GROQ_API_KEY=your_groq_api_key_here
MODEL_NAME=llama-3.3-70b-versatile
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
TEMPERATURE=0
TOP_K_RESULTS=10
CHUNK_SIZE=1200
CHUNK_OVERLAP=200
DATA_FOLDER=./data
OUTPUT_FOLDER=./outputs
```

---

## â—ˆ Usage

```bash
# First run â€” builds the FAISS index automatically
python main.py

# Force re-index (after adding new documents)
python main.py --rebuild
```

Type your question at the prompt. Type `exit` or `quit` to stop.

---

## â—ˆ Example Questions to Try

```
â—†  "How did Adobe's net income perform in FY2025 vs FY2024?"
â—†  "What is Adobe's revenue breakdown by segment for FY2024?"
â—†  "How did the Publishing and Advertising segment compare to others?"
â—†  "What is Adobe's FY2026 earnings per share guidance?"
â—†  "How did Digital Media ARR grow year-over-year?"
â—†  "What risks did Adobe highlight in their most recent 10-K?"
```

---

<div align="center">

```
Built with  âš¡ Groq  Â·  ğŸ¦œ LangChain  Â·  ğŸ¤— HuggingFace  Â·  ğŸ” FAISS
```

*Answers grounded in documents. Never outside them.*

</div>
